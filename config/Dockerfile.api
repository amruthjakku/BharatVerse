# Dockerfile for Enhanced FastAPI backend with AI capabilities
FROM python:3.11-slim

# Install system dependencies for AI models
RUN apt-get update && apt-get install -y \
    build-essential \
    gcc \
    g++ \
    portaudio19-dev \
    python3-pyaudio \
    ffmpeg \
    git \
    wget \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install uv
RUN curl -LsSf https://astral.sh/uv/install.sh | sh
ENV PATH="/root/.cargo/bin:$PATH"

WORKDIR /app

# Copy project configuration
COPY pyproject.toml .
COPY requirements.txt .

# Install Python dependencies with uv
RUN uv pip install --system -e .

# Create models cache directory
RUN mkdir -p /app/models_cache
ENV TRANSFORMERS_CACHE=/app/models_cache
ENV TORCH_HOME=/app/models_cache

# Copy application code
COPY . .

# Pre-download AI models (optional, for faster startup)
RUN python -c "import whisper; whisper.load_model('base')" || echo "Whisper model download failed"
RUN python -c "from transformers import pipeline; pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment-latest')" || echo "Sentiment model download failed"

EXPOSE 8000

# Use enhanced API if available, fallback to main
CMD ["python", "-c", "import os; exec('python api/enhanced_main.py' if os.path.exists('api/enhanced_main.py') else 'uvicorn core.api_service:app --host 0.0.0.0 --port 8000 --reload')"]

